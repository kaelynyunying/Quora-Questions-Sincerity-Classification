{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306122\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "print(str(len(train['question_text'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kaely\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Loading gensim and nltk libraries\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import logging\n",
    "import pyLDAvis.gensim\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "#Libraries for Topic Modelling Visualization\n",
    "try:\n",
    "    import pyLDAvis.gensim\n",
    "except ImportError:\n",
    "    ValueError(\"SKIP: please install pyLDAvis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for lemmatization and stemming\n",
    "def preprocess(text):\n",
    "    try:\n",
    "        result = []\n",
    "        for token in gensim.utils.simple_preprocess(text):\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "                result.append(lemmatize_stemming(token))\n",
    "        #print(result)\n",
    "        return result\n",
    "    except:\n",
    "        return []\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing is done.\n"
     ]
    }
   ],
   "source": [
    "train['question_text'] = train['question_text'].map(preprocess)\n",
    "print('Pre-processing is done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [quebec, nationalist, provinc, nation]\n",
       "1                [adopt, encourag, peopl, adopt, shop]\n",
       "2    [veloc, affect, time, veloc, affect, space, ge...\n",
       "3                [otto, guerick, magdeburg, hemispher]\n",
       "4    [convert, montra, helicon, mountain, bike, cha...\n",
       "5    [gaza, slowli, auschwitz, dachau, treblinka, p...\n",
       "6    [quora, automat, conserv, opinion, report, lib...\n",
       "7                   [crazi, wash, wipe, groceri, germ]\n",
       "8         [thing, dress, moder, differ, dress, modest]\n",
       "9    [phase, ignor, peopl, love, complet, disregard...\n",
       "Name: question_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['question_text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nation\n",
      "1 nationalist\n",
      "2 provinc\n",
      "3 quebec\n",
      "4 adopt\n",
      "5 encourag\n",
      "6 peopl\n",
      "7 shop\n",
      "8 affect\n",
      "9 geometri\n",
      "10 space\n",
      "Dictionary is built.\n"
     ]
    }
   ],
   "source": [
    "### building dictionary for LDA\n",
    "dictionary = gensim.corpora.Dictionary(train['question_text'])\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "print('Dictionary is built.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=5, no_above=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(143, 1), (230, 1), (1613, 1), (2073, 1), (2567, 2), (2609, 1), (2670, 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate Bag of Words on the data set\n",
    "bow_corpus = [dictionary.doc2bow(qn) for qn in train['question_text']]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#generate TFIDF matrix\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#run LDA using Bag of Words\n",
    "#Set Parameters\n",
    "num_topics = 5\n",
    "\n",
    "#change num_topics if want to change the number of topics generated\n",
    "lda_model_bow = gensim.models.LdaMulticore(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=2, workers=2)\n",
    "for idx, topic in lda_model_bow.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Assumptions from 20, 40 , 60, 80, 100 Assume that there are 100 topics available "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Set up Topic Model based on bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_bow = LdaModel(corpus=bow_corpus, id2word=dictionary, iterations=50, num_topics=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether topics generated are human-interpretable, we will use both umass score and cv score to evalute the topics generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  -5.822717611510448\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score using u_mass\n",
    "coherence_model_lda_umas = CoherenceModel(model=lda_model_bow, corpus=bow_corpus, dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda_umas = coherence_model_lda_umas.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_umas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence_Measure(seg=<function s_one_pre at 0x0000021512384268>, prob=<function p_boolean_document at 0x0000021512384488>, conf=<function log_conditional_probability at 0x000002151242E1E0>, aggr=<function arithmetic_mean at 0x000002151242E950>)\n"
     ]
    }
   ],
   "source": [
    "#View the pipeline parameters for one coherence model\n",
    "#By pipeline parameters, we mean the functions being used to calculate segmentation, probability estimation, confirmation measure and aggregation\n",
    "print(coherence_model_lda_umas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visualize Topic Models --> TAKES TOO LONG TO RUN OMG \n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(lda_model_bow, bow_corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cant seem to run using this method :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using c_v\n",
    "# coherence_model_lda_cv = CoherenceModel(model=lda_model_bow, texts=bow_corpus, dictionary=dictionary, coherence='c_v')\n",
    "# coherence_lda_cv = coherence_model_lda_cv.get_coherence()\n",
    "# print('\\nCoherence Score: ', coherence_lda_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#View the pipeline parameters for one coherence model\n",
    "#By pipeline parameters, we mean the functions being used to calculate segmentation, probability estimation, confirmation measure and aggregation\n",
    "print(coherence_model_lda_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to find the optimal number of topics.We need to build many LDA models with different values of the number of topics (k) and pick the one that gives the highest coherence value. Choosing a ‘k’ that marks the end of a rapid growth of topic coherence usually offers meaningful and interpretable topics. Picking an even higher value can sometimes provide more granular sub-topics. If you see the same keywords being repeated in multiple topics, it’s probably a sign that the ‘k’ is too large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the most optimal topics using U_mass Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a model list and plot Coherence score against a number of topics\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=bow_corpus, start=20, limit=100, step=20)\n",
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "limit=100; start=20; step=20;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows that coherence score increases with the number of topics, with a decline between 15 to 20.Now, choosing the number of topics still depends on your requirement because topic around 33 have good coherence scores but may have repeated keywords in the topic. Topic coherence gives you a good picture so that you can take better decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "https://markroxor.github.io/gensim/static/notebooks/topic_coherence_tutorial.html#topic=1&lambda=1&term=\n",
    "https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#run LDA using TFIDF\n",
    "#change num_topics if want to change the number of topics generated\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=20, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
